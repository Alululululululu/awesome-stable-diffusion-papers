# Awesome Stable Diffusion Papers

A curated list of papers related to Stable Diffusion.

## Contributing
Please feel free to send me [pull requests](https://github.com/Alululululululu/awesome-stable-diffusion-papers/pulls) (or [issues](https://github.com/Alululululululu/awesome-stable-diffusion-papers/issues)) to add papers/talks/demo etc.

## Table of Contents
- [Basic Diffusion Models](#basic-diffusion-models)
- [Image Editing Based on Iterative Denoising Process](#image-editing-based-on-iterative-denoising-process)
- [Image Generation Guided by Explicit Classifiers](#image-generation-guided-by-explicit-classifiers)
- [Multimodal Image Generation Guided by CLIP Models](#multimodal-image-generation-guided-by-clip-models)
- [Text-to-Image Models Based on Implicit Classifiers](#text-to-image-models-based-on-implicit-classifiers)
- [Regulating Generation in Implicit Classifier-Guided Process](#regulating-generation-in-implicit-classifier-guided-process)
- [Adding Conditional Control to Text-to-Image Diffusion Models](#adding-conditional-control-to-text-to-image-diffusion-models)
- [Generative Models for Feature Learning and Pretraining](#generative-models-for-feature-learning-and-pretraining)
- [Text-to-Video Generation](#text-to-video-generation)
- [Image Animation](#image-animation)
- [Pose to Video Generation](#pose-to-video-generation)
- [Stable Diffusion Series Models (Stability AI)](#stable-diffusion-series-models-stability-ai)
- [LoRA Series](#lora-series)

## Basic Diffusion Models
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| [DDPM: Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239) | NeurIPS | 2020 | [GitHub](https://github.com/hojonathanho/diffusion) |
| [DDIM: Denoising Diffusion Implicit Models](https://arxiv.org/abs/2010.02502) | ICLR | 2021 | [GitHub](https://github.com/ermongroup/ddim) |
| [Generative Modeling by Estimating Gradients of the Data Distribution](https://arxiv.org/abs/1907.05600) | NeurIPS | 2019 | [GitHub](https://github.com/ermongroup/ncsn)|
| [Score-Based Generative Modeling through Stochastic Differential Equations](https://arxiv.org/abs/2011.13456) | ICLR | 2021 | [GitHub](https://github.com/yang-song/score_sde) |
| [Improved Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2102.09672) | ICML | 2021 |[GitHub](https://github.com/openai/improved-diffusion?tab=readme-ov-file) |
| [Variational Diffusion Models](https://arxiv.org/abs/2107.00630) | NeurIPS | 2021 | [GitHub](https://github.com/google-research/vdm) |

## Image Editing Based on Iterative Denoising Process
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| [IVLR: Conditioning Method for Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/xxxxxxx) | | | |
| [SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations](https://arxiv.org/abs/xxxxxxx) | | | |
| [RePaint: Inpainting using Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/xxxxxxx) | | | |

## Image Generation Guided by Explicit Classifiers
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| [Diffusion Models Beat GANs on Image Synthesis](https://arxiv.org/abs/2105.05233) | | | |

## Multimodal Image Generation Guided by CLIP Models
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| [More Control for Free! Image Synthesis with Semantic Diffusion Guidance](https://arxiv.org/abs/xxxxxxx) | | | |
| [Blended Diffusion for Text-driven Editing of Natural Images](https://arxiv.org/abs/xxxxxxx) | | | |
| [DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation](https://arxiv.org/abs/xxxxxxx) | | | |
| [Diffusion Models Already Have a Semantic Latent Space](https://arxiv.org/abs/xxxxxxx) | | | |
| [GLIGEN: Open-Set Grounded Text-to-Image Generation](https://arxiv.org/abs/xxxxxxx) | CVPR | 2023 | |

## Text-to-Image Models Based on Implicit Classifiers
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/xxxxxxx) | | | |
| [Multi-Concept Customization of Text-to-Image Diffusion](https://arxiv.org/abs/xxxxxxx) | | | |
| [WÃ¼rstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models](https://arxiv.org/abs/xxxxxxx) | | | |

## Regulating Generation in Implicit Classifier-Guided Process
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| [Imagic: Text-Based Real Image Editing with Diffusion Models](https://arxiv.org/abs/xxxxxxx) | | | |
| [UniTune: Text-Driven Image Editing by Fine Tuning an Image Generation Model on a Single Image](https://arxiv.org/abs/xxxxxxx) | | | |
| [DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation](https://arxiv.org/abs/xxxxxxx) | | | |
| [DiffEdit: Diffusion-based Semantic Image Editing with Mask Guidance](https://arxiv.org/abs/xxxxxxx) | | | |
| [Prompt-to-Prompt Image Editing with Cross-Attention Control](https://arxiv.org/abs/xxxxxxx) | | | |

## Adding Conditional Control to Text-to-Image Diffusion Models
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| [Adding Conditional Control to Text-to-Image Diffusion Models](https://arxiv.org/abs/xxxxxxx) | ControlNet | | |
| [Putting People in Their Place: Affordance-Aware Human Insertion into Scenes](https://arxiv.org/abs/xxxxxxx) | | | |
| [BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion](https://arxiv.org/abs/xxxxxxx) | ICCV | 2023 | |

## Generative Models for Feature Learning and Pretraining
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| [DreamTeacher: Pretraining Image Backbones with Deep Generative Models](https://arxiv.org/abs/xxxxxxx) | ICCV | 2023 | |

## Text-to-Video Generation
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| [Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation](https://arxiv.org/abs/xxxxxxx) | | | |
| [StyleInV: A Temporal Style Modulated Inversion Network for Unconditional Video Generation](https://arxiv.org/abs/xxxxxxx) | ICCV | 2023 | |
| [ControlVideo: Training-free Controllable Text-to-Video Generation](https://arxiv.org/abs/xxxxxxx) | ICLR | 2024 | |

## Image Animation
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| [Person image synthesis via denoising diffusion model](https://arxiv.org/abs/xxxxxxx) | | | |
| [Conditional image-to-video generation with latent flow diffusion models](https://arxiv.org/abs/xxxxxxx) | | | |
| [Leo: Generative latent image animator for human video synthesis](https://arxiv.org/abs/xxxxxxx) | | | |
| [Dreampose: Fashion video synthesis with stable diffusion](https://arxiv.org/abs/xxxxxxx) | | | |

## Pose to Video Generation
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| [Disco: Disentangled control for referring human dance generation in real world](https://arxiv.org/abs/xxxxxxx) | based on ControlNet | | |
| [Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation](https://arxiv.org/abs/xxxxxxx) | | | |
| [Magicanimate: Temporally consistent human image animation using diffusion model](https://arxiv.org/abs/xxxxxxx) | arxiv | | |
| [UniAnimate: Taming Unified Video Diffusion Models for Consistent Human Image Animation](https://arxiv.org/abs/xxxxxxx) | | | |

## Stable Diffusion Series Models (Stability AI)
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| [High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752) | | v1.0 | |
| [Stable Diffusion](https://github.com/Stability-AI/stablediffusion) | | v2.0 | |
| [Scaling Rectified Flow Transformers for High-Resolution Image Synthesis](https://arxiv.org/abs/xxxxxxx) | | v3.0 | |

## LoRA Series
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| [Lora](https://arxiv.org/abs/xxxxxxx) | | | |
| [QLora](https://arxiv.org/abs/xxxxxxx) | | | |
| [AdaLora](https://arxiv.org/abs/xxxxxxx) | | | |
| [LongLora](https://arxiv.org/abs/xxxxxxx) | | | |
| [SLora](https://arxiv.org/abs/xxxxxxx) | | | |
| [oLora](https://arxiv.org/abs/xxxxxxx) | | | |
