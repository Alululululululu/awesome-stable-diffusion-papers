# Awesome Stable Diffusion Papers

A curated list of papers related to Stable Diffusion.

## Contributing
Please feel free to send me [pull requests](https://github.com/Alululululululu/awesome-stable-diffusion-papers/pulls) (or [issues](https://github.com/Alululululululu/awesome-stable-diffusion-papers/issues)) to add papers/talks/demo etc.


## Table of Contents
- [Basic Diffusion Models](#basic-diffusion-models)
- [Image Editing Based on Iterative Denoising Process](#image-editing-based-on-iterative-denoising-process)
- [Image Generation Guided by Explicit Classifiers](#image-generation-guided-by-explicit-classifiers)
- [Multimodal Image Generation Guided by CLIP Models](#multimodal-image-generation-guided-by-clip-models)
- [Text-to-Image Models Based on Implicit Classifiers](#text-to-image-models-based-on-implicit-classifiers)
- [Regulating Generation in Implicit Classifier-Guided Process](#regulating-generation-in-implicit-classifier-guided-process)
- [Adding Conditional Control to Text-to-Image Diffusion Models](#adding-conditional-control-to-text-to-image-diffusion-models)
- [Generative Models for Feature Learning and Pretraining](#generative-models-for-feature-learning-and-pretraining)
- [Text-to-Video Generation](#text-to-video-generation)
- [Image Animation](#image-animation)
- [Pose to Video Generation](#pose-to-video-generation)
- [Stable Diffusion Series Models (Stability AI)](#stable-diffusion-series-models-stability-ai)
- [LoRA Series](#lora-series)

## Basic Diffusion Models
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| DDPM: Denoising Diffusion Probabilistic Models | | | |
| DDIM: Denoising Diffusion Implicit Models | | | |


## Image Editing Based on Iterative Denoising Process
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| IVLR: Conditioning Method for Denoising Diffusion Probabilistic Models | | | |
| SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations | | | |
| RePaint: Inpainting using Denoising Diffusion Probabilistic Models | | | |

## Image Generation Guided by Explicit Classifiers
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| Diffusion Models Beat GANs on Image Synthesis | | | |

## Multimodal Image Generation Guided by CLIP Models
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| More Control for Free! Image Synthesis with Semantic Diffusion Guidance | | | |
| Blended Diffusion for Text-driven Editing of Natural Images | | | |
| DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation | | | |
| Diffusion Models Already Have a Semantic Latent Space | | | |
| GLIGEN: Open-Set Grounded Text-to-Image Generation | CVPR 2023 | | |

## Text-to-Image Models Based on Implicit Classifiers
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| Classifier-Free Diffusion Guidance | | | |
| Multi-Concept Customization of Text-to-Image Diffusion | | | |
| WÃ¼rstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models | | | |

## Regulating Generation in Implicit Classifier-Guided Process
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| Imagic: Text-Based Real Image Editing with Diffusion Models | | | |
| UniTune: Text-Driven Image Editing by Fine Tuning an Image Generation Model on a Single Image | | | |
| DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation | | | |
| DiffEdit: Diffusion-based Semantic Image Editing with Mask Guidance | | | |
| Prompt-to-Prompt Image Editing with Cross-Attention Control | | | |

## Adding Conditional Control to Text-to-Image Diffusion Models
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| Adding Conditional Control to Text-to-Image Diffusion Models | ControlNet | | |
| Putting People in Their Place: Affordance-Aware Human Insertion into Scenes | | | |
| BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion | ICCV 2023 | | |

## Generative Models for Feature Learning and Pretraining
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| DreamTeacher: Pretraining Image Backbones with Deep Generative Models | ICCV 2023 | | |

## Text-to-Video Generation
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation | | | |
| StyleInV: A Temporal Style Modulated Inversion Network for Unconditional Video Generation | ICCV 2023 | | |
| ControlVideo: Training-free Controllable Text-to-Video Generation | ICLR 2024 | | |

## Image Animation
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| Person image synthesis via denoising diffusion model | | | |
| Conditional image-to-video generation with latent flow diffusion models | | | |
| Leo: Generative latent image animator for human video synthesis | | | |
| Dreampose: Fashion video synthesis with stable diffusion | | | |

## Pose to Video Generation
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| Disco: Disentangled control for referring human dance generation in real world | based on ControlNet | | |
| Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation | | | |
| Magicanimate: Temporally consistent human image animation using diffusion model | arxiv | | |
| UniAnimate: Taming Unified Video Diffusion Models for Consistent Human Image Animation | | | |

## Stable Diffusion Series Models (Stability AI)
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| High-Resolution Image Synthesis with Latent Diffusion Models | https://arxiv.org/abs/2112.10752 | v1.0 | |
| | https://github.com/Stability-AI/stablediffusion | v2.0 | |
| Scaling Rectified Flow Transformers for High-Resolution Image Synthesis | | v3.0 | |

## LoRA Series
| Title | Venue | Year | Link/Code |
| --- | --- | --- | --- |
| Lora | | | |
| QLora | | | |
| AdaLora | | | |
| LongLora | | | |
| SLora | | | |
| oLora | | | |
